[{"categories":null,"content":"Recently I stumbled upon an interesting issue in one of our services. When going through our Grafana dashboards I have discovered that time spent in GC for this service is abnormally high. Immediately I started investigating this issue. The investigation was pretty quick and an issue was rather simple but it gave us a significant performance boost. So I decided to share it with you and shed some light on how adaptive heap sizing in jvm works and how it can sometimes be a problem. ","date":"2020-05-27","objectID":"/xms_good_practice/:0:0","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"Service overview First, I want to tell you a little more about the service I was working with. In my opinion, it is the most complicated service our team created. Mostly because it utilizes 3 databases (MongoDb(aggregated statistics for single notification), Cassandra (event store) and ElasticSearch (notifications full text search)) it internally uses Kafka (queue before DBs for reliability purposes) and was written in Spring's Reactor. The business purpose of this service is to track all notifications sent from our infrastructure. It aggregates few different events: When the notification was sent If the notification was failed to send When the user opened a notification When the user clicked in any of the links inside of the notification During the day we are observing traffic around few thousands rps (requests per second). Here is an example of traffic from the most common day: And normal p99 of responses time form tracker service: As you can see it is disturbingly high. The tracking service is running at 10 instances in a production environment. Every instance has 3GB of memory committed as uses 2 processor cores. In total it gives us 30GB of memory and 20 processor cores. Which I think is a lot for the work it has to do. ","date":"2020-05-27","objectID":"/xms_good_practice/:0:1","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"Looking through Grafana dashboards I have discovered that most tracking service instances are spending 30 seconds out of minute in GC. Here is how it looks like on charts: Also, a number of GC collections were really high, almost 15k collection per 10 minutes: I began investigation. I have downloaded gc.log for one instance. Using JClarity's Censum I have discovered that allocation rate was around 1GB and 1.8GB in peaks, which was pretty high. Moreover, there was huge percent of premature promotions, to be exact 52%. I have assumed that this is because of this high allocation rates. In the next step I have created and downloaded heap dump for this instance, to check contents of the heap. It was quite a surprise when I discovered that it‚Äôs size was only 42MB. With this allocation rate, there was no surprise that JVM was spending thirty seconds out of minute in GC. The percent of premature promotions was that high because heap was only 42MB in size and object allocation rate was more than 1GB. I cannot believe we deliberately set that small heaps, so I have checked the jvm properties from our configuration, and the only heap size property that was set was -Xmx2G. My first reflex was to add -Xms property which I did right away. ","date":"2020-05-27","objectID":"/xms_good_practice/:0:2","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"Adding -Xms along -Xmx I have set -Xms1g and -Xmx1g and here are the results of this change: and As we can see time spent in a GC was reduced significantly. Moreover, thanks to that response times from our service was also reduced ","date":"2020-05-27","objectID":"/xms_good_practice/:0:3","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"Why this helped and why previously heap was only 40mb? When we don‚Äôt set -Xms flag explicitly the initial heap size will be set to 1/64 of all available memory. Which in our case was around 31MB. We can control how fast JVM is resizing it‚Äôs heap by setting flags: -XX:MinHeapFreeRatio and -XX:MaxHeapFreeRatio which defaults are 40% and 70%. This means that JVM will enlarge its heap after full gc when percent of free space is less than 40. On the other, hand heap size will shrink after full GC if there is more than 70% space free. JVM is less eager to reduce heap size because it is more complicated operation and will take more time which will significantly affect application performance. This is default resizing policy and because objects that were allocated by our application was dying young and most of them were removed after full GC we could never reach this MinHeapFreeRatio threshold. This is fragment of our GC log: 463.462: [GC (Allocation Failure) 463.462: [ParNew Desired survivor size 425984 bytes, new threshold 6 (max 6) - age 1: 386048 bytes, 386048 total : 7997K-\u003e606K(8000K), 0.0055859 secs] 80902K-\u003e73901K(178220K) icms_dc=13 , 0.0056746 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 463.473: [CMS-concurrent-abortable-preclean: 0.005/0.043 secs] [Times: user=0.06 sys=0.01, real=0.04 secs] 463.473: [GC (CMS Final Remark) [YG occupancy: 3754 K (8000 K)] 463.473: [Rescan (parallel) , 0.0040316 secs] 463.477: [weak refs processing, 0.0000878 secs] 463.477: [class unloading, 0.0269731 secs] 463.504: [scrub symbol table, 0.0243151 secs] 463.529: [scrub string table, 0.0014955 secs] [1 CMS-remark: 73295K(170220K)] 77049K(178220K), 0.0570683 secs] [Times: user=0.06 sys=0.00, real=0.06 secs] 463.531: [CMS-concurrent-sweep-start] In line 14 we can see that live objects were occupying 77049KB out of 178220KB available memory on the heap. Which means there was almost 60 percent of free space. And this was rather a standard situation after each full GC. This problem occurred because we were using Concurrent Mark Sweep collector. CMS does not support adaptive sizing policy, which is default for Parallel and G1 collectors. With adaptive sizing there are three criteria taken into account when deciding if the heap should be resized: Desired maximum GC pause goal - if the GC pause time is greater than the pause time goal then reduce the sizes of the generations to better attain the goal. Desired application throughput goal - if the pause time goal is being met then consider the application‚Äôs throughput goal. If the application‚Äôs throughput goal is not being met, then increase the sizes of the generations to better attain the goal. Minimum footprint - if both the pause time goal and the throughput goal are being met, then the size of the generations are decreased to reduce footprint. However we were using CMS GC so we cannot rely on adaptive sizing. But we can compute how large heap we need. ","date":"2020-05-27","objectID":"/xms_good_practice/:0:4","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"Looking at GC logs and finding the right values for Eden and tenuring space Right now we have defined our heap size and to be 1GB. But we have not specified the size of generations. Due to that CMS is creating really small Eden there would be still a lot of collections in young generation. If we look again at allocation rates we can see that most of the time we are allocating around 800mb per second. It would be nice not to have more than one collection per second. Our service is using around 200-300mb of memory for Spring and configuration and rest of the objects have really short lifespan. So we can set young generation size to 600mb an old size to 400mb. Here are the results of this change: Typical young collection time (0.01 sec): 5968.202: [GC (Allocation Failure) 5968.202: [ParNew Desired survivor size 31457280 bytes, new threshold 6 (max 6) - age 1: 1232984 bytes, 1232984 total - age 2: 2318608 bytes, 3551592 total - age 3: 302888 bytes, 3854480 total - age 4: 938800 bytes, 4793280 total - age 5: 69456 bytes, 4862736 total - age 6: 56680 bytes, 4919416 total : 498270K-\u003e5506K(552960K), 0.0078395 secs] 615145K-\u003e123035K(987136K) icms_dc=0 , 0.0079445 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] Typical old collection pause time(0.21sec): 27.719: [CMS-concurrent-abortable-preclean: 0.849/4.488 secs] [Times: user=11.33 sys=0.83, real=4.49 secs] 27.720: [GC (CMS Final Remark) [YG occupancy: 256247 K (552960 K)] 27.720: [Rescan (parallel) , 0.1079998 secs] 27.828: [weak refs processing, 0.0002720 secs] 27.828: [class unloading, 0.0671273 secs] 27.895: [scrub symbol table, 0.0297383 secs] 27.925: [scrub string table, 0.0020253 secs] [1 CMS-remark: 46556K(434176K)] 302804K(987136K), 0.2098574 secs] [Times: user=0.44 sys=0.10, real=0.21 secs] 27.930: [CMS-concurrent-sweep-start] 27.961: [CMS-concurrent-sweep: 0.030/0.031 secs] [Times: user=0.15 sys=0.02, real=0.03 secs] 27.961: [CMS-concurrent-reset-start] 27.962: [CMS-concurrent-reset: 0.001/0.001 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] Number of collections per 10 minutes: Time spent in GC per minute: Also, overall usage of the processor was reduced thanks to that changes (first change at 11:00 and second at 16:00): ","date":"2020-05-27","objectID":"/xms_good_practice/:0:5","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"Summary To sum up, CMS does not have adaptive sizing policy and all changes to heap size are based only on free space after full GC. Because of that, it is good practice to set not only max heap size by also min heap size, which should be based on how your application allocates memory and how much does it need for normal functioning. Another thing you should be cautious about is how often GC is being performed and how long does it take to clean heap form garbage. Moreover, I want to point out how important it is to look at GC metrics, analyze gc.log from time to time, and adjust JVM tuning to your actual workload. All the tuning I did to this JVM is fine right now but after a few months, application or traffic could change and we will end up with a poorly tuned application. ","date":"2020-05-27","objectID":"/xms_good_practice/:0:6","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"References GC ergonomics - Oracle docs jClarity Censum ","date":"2020-05-27","objectID":"/xms_good_practice/:1:0","tags":null,"title":"Why is it good practice to set -Xms along -Xmx java flag while using Concurrent Mark Sweep (CMS) collector?","uri":"/xms_good_practice/"},{"categories":null,"content":"So you have JVM based service (A) that is communicating with another service (B) using some kind of HTTP client. You know what you are doing so you gathered metrics statistics from your dependency. Especially it‚Äôs response times. Let‚Äôs assume that p99 of its response times form service B are 200ms. Also, this service is fairly close to you for example in the same data center. You adjusted your timeouts accordingly, for example, you‚Äôve set connection timeout to 50ms and socket timeout to 250ms. Everything works fine but you are really thorough, have great observability in your service and monitor metrics regularly. One day you noticed something: Wait, what? How is this even possible? You have set timeouts and in the worst-case scenario, your requests should be timed out after 250ms. Connection timeout restricts how long we will wait until the connection is established. So the result can be either an open connection or unreachable host. So there shouldn‚Äôt be any problems. Let‚Äôs take a look at socket timeout maybe we can find something interesting. ‚ÄúTalk is cheap, show me the code‚Äù To get a better understanding of whats going on we could write a simple socket server and simple client. All of the code was written in java 11, on AdoptOpenJDK 11.0.4 Here is the code of server: public class Main { public static void main(String[] args) throws IOException, InterruptedException { //starting server try (var listener = new ServerSocket(59090)) { System.out.println(\"The simple server is running...\"); //message to send byte[] test = {1}; while (true) { try (var socket = listener.accept()) { System.out.println(\"Accepted connection\"); OutputStream outputStream = socket.getOutputStream(); for (int i = 0; i \u003c 200; i++) { outputStream.write(test); } outputStream.close(); } } } } } It is not rocket science, we are creating a new instance of SocketServer running on port 59090. Next in line (9) we prepare the message that we will send and it is a single byte, we will be sending it 200 times. Next, we have an infinite loop that will wait for client connections and when this happens we will send him our message. Now, let‚Äôs take a look at the client: public class SimpleClient { public static void main(String[] args) throws IOException { //creating socket with timeout var socket = new Socket(\"localhost\", 59090); socket.setSoTimeout(100); //byte array to store output byte[] b = new byte[1024]; long start = System.currentTimeMillis(); var input = socket.getInputStream(); var read = input.read(b, 0, 300); var offset = 0; while (offset \u003c= 200 \u0026\u0026 read != -1) { offset += read; System.out.println(\"read: \" + read + \"bytes\"); read = input.read(b, offset, 200); } long finish = System.currentTimeMillis(); long time = finish - start; System.out.println(\"Operation took: \" + time); System.out.println(\"In total read \" + offset + \" bytes.\"); } } Not much to see here, we are creating new Socket instance that will connect to our localhost on port 59090 then we set soTimout to 100ms this is what we will be monitoring. Next, there is a prepared byte array to store the response from our server. With everything prepared we can start reading. We know that we should read 200 bytes so we will read until we have collect 200 bytes and there is something to read. At the end to check if everything went well and we read the amount of bytes that were expected we can print our reading offset. (Function InputStream.read(byte b[], int off, int len) returns amount of bytes that were read). Fantastic we have written some code so we can run it and measure how long it took to read the whole message. I ran it a few times and got an average response of 17ms and we have much time to spare until we reach the timeout. Now lets see what happens when connection becomes slower. To simulate it we will add sleep in our server just after we accept new connection: System.out.println(\"Accepted connection\"); sleep(150); OutputStream outputStream = socket.getOutputStream(); After running again our code ","date":"2019-12-13","objectID":"/timeouts/:0:0","tags":null,"title":"Why my HTTP request did not timed out? Quick tour inside JDK and OkHttpClient for better understanding of timeouts","uri":"/timeouts/"},{"categories":null,"content":"But how does it know how many bytes should it read? The answer to this question is actually pretty simple. HTTP response has a predefined scheme. First of all, we have Status line which contains status code, next we have headers and finally message body. Headers and body are separated with CRLF Also one of the headers is Content-Length which indicates how long message body will be. So while receiving response from another service via HTTP/1.1 we can calculate when to stop reading from the socket after receiving an appropriate amount of bytes. Summing up After reading this short article you should know how timeouts work inside of JDK and why your request to another service took longer than expected. The Most important piece of knowledge you should remember is that when you set socketTimeout for example on RestTemplate while using Spring you set a timeout for every single read form socket which effectively becomes time from last bit of information after your connection will be interrupted. You should keep it in mind when you set timeouts next time in your application and adjust them accordingly. Fortunately since 3.12.0 version of OkHttp client you can specify call timeout OkHttpClient.Builder.callTimeout() which will limit whole operation time. That all from me, thank you all for reading my first post. Feel free to let me know how you liked it, also I encourage you to comment, ask questions and share the knowledge with your coworkers. ","date":"2019-12-13","objectID":"/timeouts/:0:1","tags":null,"title":"Why my HTTP request did not timed out? Quick tour inside JDK and OkHttpClient for better understanding of timeouts","uri":"/timeouts/"},{"categories":null,"content":"References Source code of examples used in this post OkHttp JDK ","date":"2019-12-13","objectID":"/timeouts/:1:0","tags":null,"title":"Why my HTTP request did not timed out? Quick tour inside JDK and OkHttpClient for better understanding of timeouts","uri":"/timeouts/"},{"categories":null,"content":"Hi, my name is Marcin, and since I remember I loved to know how things work. When I was young I disassembled a lot of toys and one old boom box. Unfortunately, I was not able to assemble all of them again. In high school I fell for physics and astronomy I could finally deepen the secrets of the universe and just before going to university I discovered how much fun programming, so I decided to study Computer Science. Since then a lot of has changed I have learned a lot, I started working, I met a lot of amazing people that helped me extend my knowledge. I got a dog (he is really cute BTW üòâ). Some time ago something has changed I don‚Äôt know what yet but I recall my love for exploring and deeply understanding things, so I started to read JDK code, dig into JVM internals, try to understand how Linux kernel works and how it affects the performance of applications. Now I want to share this knowledge and my discoveries with others, so I started this blog. I am deeply focused on JVM internals and performance engineering right now but do a lot more in my free time. I really like photography, especially animal and landscape photography and my dream is to one day direct my own short film. Feel free to contact me on social media, any time you want. ","date":"2019-12-11","objectID":"/about/:0:0","tags":null,"title":"","uri":"/about/"},{"categories":null,"content":"Public Speaking I am open to public speaking opportunities. ","date":"0001-01-01","objectID":"/public_speaking/:0:0","tags":null,"title":"","uri":"/public_speaking/"},{"categories":null,"content":"Speaking history Event Role Topic Date Recording Jugademy Speaker Service Mesh Introduction 06.2022 Youtube Allegro Technical Platform Meeting Speaker How I almost deleted Allegro because of Consul UI design and human error 06.2022 Slides DevDays Europe Panelist Serverless and Service Mesh ‚Äì what is Next? 02.2022 Allegro Tech Labs Trainer System Design Workshop 04.2021 and 12.2021 Allegro Tech Meeting Track Host Security track 09.2021 Allegro Tech Meeting internal Track Host Software track 09.2021 4Developers Speaker Wszystko co chcia≈Çe≈õ wiedzieƒá o wƒÖtkach a ba≈Çe≈õ siƒô zapytaƒá 05.2021 Youtube Allegro Tech Meeting Speaker Wszystko co chcia≈Çe≈õ wiedzieƒá o wƒÖtkach a ba≈Çe≈õ siƒô zapytaƒá 09.2020 Youtube ","date":"0001-01-01","objectID":"/public_speaking/:0:1","tags":null,"title":"","uri":"/public_speaking/"}]